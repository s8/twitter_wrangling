{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import json\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "twitter_archive.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_archive[twitter_archive.in_reply_to_status_id.notnull()]\n",
    "twitter_archive[twitter_archive.retweeted_status_user_id.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = rq.get('https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv')\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.headers['content-type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the received .tsv file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image predictions dataset from a local file\n",
    "image_predictions = pd.DataFrame.from_csv('image-predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load image predictions dataset from the URL\n",
    "image_predictions = pd.DataFrame.from_csv(io.StringIO(r.content.decode(r.encoding)), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge twitter archive and image predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(twitter_archive,image_predictions,how='inner',on='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3: Twitter via API\n",
    "\n",
    "### Set up Twitter API via tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-553e067ff128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOAuthHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsumer_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumer_secret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_access_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccess_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccess_secret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "api.wait_on_rate_limit = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download WeRateDogs Twitter archive. Takes around 30 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty array to store dictionaries retrieved via API\n",
    "tweets = []\n",
    "missing_tweets = []\n",
    "\n",
    "# use tweet_id's from our dataframe to retrieve original tweets\n",
    "for i in merged_df.tweet_id:\n",
    "    try:\n",
    "        tweets.append (api.get_status(i, tweet_mode='extended'))\n",
    "    except:\n",
    "        missing_tweets.append(i)\n",
    "        print ('tweet #', i, ' could not be located')\n",
    "            \n",
    "# write downloaded tweets to a json file and store it locally            \n",
    "with open('tweets.json', 'w') as outfile:\n",
    "    json.dump(tweets, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the downloaded and saved archive from a local .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_json ('tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge tweets with two previous datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename id columns to identical names\n",
    "tweets.rename(columns={'id':'tweet_id'},inplace=True)\n",
    "\n",
    "# merge two dataframes on the 'tweet_id' column\n",
    "we_rate_dogs = pd.merge(merged_df,tweets, how='inner', on='tweet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Assess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "we_rate_dogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "we_rate_dogs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(we_rate_dogs.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Duplicate, zero and redundant data\n",
    "First let's assess whether there are any columns that duplicate data, contain no data whatsoever or that are irrelevant for the purposes of our analysis. Let's make empty lists which we will populate over the course of our assessment and drop remove them from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_columns = []\n",
    "zero_columns = []\n",
    "redundant_columns = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing data in columns highlights some of the empty variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of all zero-value columns\n",
    "zero_columns.extend(['contributors','coordinates','favorited','geo','is_quote_status','possibly_sensitive','possibly_sensitive_appealable','retweeted','truncated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there is only one record in the 'place' column. What is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs[we_rate_dogs.place.notnull()].place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store this place in a separate variable and remove the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrd_place = we_rate_dogs.iloc[686]\n",
    "zero_columns.append('place')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis we will not engage in understanding social context of this account, therefore all information pertaining to retweets and replies can be considered redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant_columns.extend(['in_reply_to_status_id_x', 'in_reply_to_user_id_x',\n",
    "'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp',\n",
    "'in_reply_to_screen_name','in_reply_to_status_id_y', 'in_reply_to_status_id_str',\n",
    "'in_reply_to_user_id_y', 'in_reply_to_user_id_str','retweeted_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are source_x and source_y columns identical?\n",
    "# sum the number of times records differ and subtract from this the length of the whole dataset\n",
    "# '0' would indicate that all the records in these columns are identical\n",
    "print (sum(we_rate_dogs.source_x == we_rate_dogs.source_y) - len(we_rate_dogs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_columns.append('source_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs.drop(columns=duplicate_columns, inplace=True)\n",
    "we_rate_dogs.drop(columns=zero_columns, inplace=True)\n",
    "we_rate_dogs.drop(columns=redundant_columns,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('number if columns in the dataset: ', len(we_rate_dogs.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "we_rate_dogs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Incorrect data types.\n",
    "\n",
    "Some of the columns have "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define \n",
    "`display_text_range` column can be effectively reduced to a single `int` rather than a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(we_rate_dogs.display_text_range.apply(lambda x: 1 if x[0] > 0 else 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "\n",
    "extract the relevant value, put it into a new column and drop the old column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs['display_text_end'] = we_rate_dogs.display_text_range.apply(lambda x: x[1]).astype(int)\n",
    "we_rate_dogs.drop(columns='display_text_range', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "check if our new colum is of `int64` type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(we_rate_dogs.display_text_end[0]))\n",
    "we_rate_dogs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `user` field contains a number of interesting fields. Let's unpack some of those into our dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Unpack `followers_count` field from `user` into separate column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "Using `apply` function - unpack the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs['followers'] = we_rate_dogs.user.apply(lambda x: x['followers_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "Check the new column is in place and that it's `int64` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Unpack `favourites_count` from within `user` field into a separate column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs['total_favourites'] = we_rate_dogs.user.apply(lambda x: x['favourites_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (we_rate_dogs['total_favourites'].min())\n",
    "print (we_rate_dogs['total_favourites'].mean())\n",
    "print (we_rate_dogs['total_favourites'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "\n",
    "There should be a limited set of appications used to post tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many various sources were used to post tweets?\n",
    "we_rate_dogs.source_x.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "This kind of data is best represented as a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "we_rate_dogs.source_x = we_rate_dogs.source_x.apply(lambda x: x.split('>')[1].split('<')[0]).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test\n",
    "Check unique values in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs.source_x.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Hashtags are nested deep inside dictionaries. To be useful for analysis - they need to be extracted into a separate columnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "\n",
    "extract hashtags using the `apply` method, put them in a separate column and cast them into `category` type variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs['hashtags'] = we_rate_dogs.entities.apply(lambda x: x['hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_hashtags(x):\n",
    "    try:\n",
    "        return x[0]['text']\n",
    "    except:\n",
    "        return None\n",
    "        \n",
    "we_rate_dogs.hashtags = we_rate_dogs.hashtags.apply(lambda x: unpack_hashtags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs.hashtags.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this few hashtags they are better as a 'category' type variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs.hashtags = we_rate_dogs.hashtags.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "Check that the `hashtags` colummn is a `category` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "\n",
    "Same as hashtags - `url`s are nested deep inside dictionaries. They need to be extracted into a separate column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "Using `apply` function with a short lambda expression - extract the `url` into a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs['url'] = we_rate_dogs.entities.apply(lambda x: x['media'][0]['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "Check the new `url` column has the right information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "we_rate_dogs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "\n",
    "`timestamp` and `crated_at` columns are probably identical. If that's the case - one needs to be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first - convert timestamp into datetime format\n",
    "we_rate_dogs.timestamp = pd.to_datetime(we_rate_dogs.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip both fileds of time zone\n",
    "we_rate_dogs['timestamp'] = we_rate_dogs['timestamp'].apply(lambda x: x.replace(tzinfo=None))\n",
    "we_rate_dogs['created_at'] = we_rate_dogs['created_at'].apply(lambda x: x.replace(tzinfo=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# subtract one from the other and sum the differences to see if there's anything different between the two\n",
    "(we_rate_dogs['timestamp'] - we_rate_dogs['created_at']).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the created_at column\n",
    "we_rate_dogs.drop(columns='created_at',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "\n",
    "`doggo`, `floofer`, `pupper`, `puppo` columns are better represented as `bool`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bool(x):\n",
    "    if x=='None':\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "we_rate_dogs.doggo = we_rate_dogs.doggo.apply(to_bool)\n",
    "we_rate_dogs.floofer = we_rate_dogs.floofer.apply(to_bool)\n",
    "we_rate_dogs.pupper = we_rate_dogs.pupper.apply(to_bool)\n",
    "we_rate_dogs.puppo = we_rate_dogs.puppo.apply(to_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "Check if the columns have correct data types in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Convert `lang` column into category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs.lang = we_rate_dogs.lang.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_rate_dogs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('start date: ', we_rate_dogs.timestamp.min())\n",
    "print ('end date: ', we_rate_dogs.timestamp.max())\n",
    "duration = we_rate_dogs.timestamp.max()- we_rate_dogs.timestamp.min()\n",
    "print ('duration: ', duration)\n",
    "print ('average tweets per day: ', len(we_rate_dogs)/duration.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(duration.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets = twitter_archive[twitter_archive.retweeted_status_timestamp.notna()]\n",
    "retweets.iloc[7].expanded_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = twitter_archive.iloc[295].expanded_urls.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.expanded_urls = twitter_archive.expanded_urls.apply(lambda x: list(set(str(x).split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in twitter_archive.expanded_urls:\n",
    "    if len(i) > 1: print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.expanded_urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.iloc[295]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
